---
title: "C2C #1: Game Theory"
---
## Types of games
The most simple type of game is the one that we built in the [setup](setup.qmd) section. Cards get flipped over and you either win or lose. Not much skill...and not much fun! 

Other games like Bingo, Dreidel, and of course Snakes and Ladders can deceptively seem like you have strategic control of the game, but really this is just the "illusion of agency", since you're only, for example, rolling dice to randomize your next move. A disturbing fact: 

![](assets/eliezer_snakes.jpg) 

There are three main classes of games that do have significant strategic agency: **perfect information**, **perfect information with randomness**, and **imperfect (hidden) information**. 

We can also think about games along the axis of **fixed or random opponents** and **adversarial opponents**. 

(There are also other game classes like sequential vs. simultaneous action games.) 

| Game/Opponent     | Fixed/Random Opponent | Adversarial Opponent | 
|------------|-----------|--------|
| **No Player Agency/Decisions**      | Candy Land, War, Dreidel, Bingo, Snakes and Ladders         | Blackjack dealer
| **Perfect Info**     | Puzzles, Rubix cube  | Tictactoe, Checkers, Chess, Arimaa, Go, Connect Four |
| **Perfect Info with Randomness**     | Monopoly, Risk   | Backgammon |
| **Imperfect Info**    | Wordle, Blackjack  | Poker, Rock Paper Scissors, Figgie, StarCraft |

### Perfect information games
Perfect information games like Chess and Go are complex and have been the focus of recent AI research, much like poker. Solving these games can theoretically be done using **backward induction**, which means starting from possible end positions and working backwards. 

### Imperfect information games
Here we want to primarily focus on the bottom right of this chart: imperfect information games with an adversarial opponent. 

These games cannot be solved in the same way as perfect information games because we don't know what state of the game we are in (we'll look at this more in [Game Trees](3_gametrees.qmd)). 

Imperfect information games are representative of real world situations where information is usually incomplete, e.g. job interviews, investments, dating, and negotiations.

### Winning games
The goal of a game is to maximize the "utility", which is usually a score or money or some kind of value. 

There are two fundamental strategies: 

1. **Exploiting opponent weaknesses:** Capitalize on specific flaws or tendencies of opponents, while putting yourself at risk if the opponent adapts well.

2. **Being unexploitable:** Playing a balanced, theoretically sound strategy, also known as "game theory optimal". This does not maximize against weaker opponents, but rather aims to minimize losses against any possible opponents. 

## Rock Paper Scissors
![Image by [Enzoklop](https://en.wikipedia.org/wiki/Rock_paper_scissors#/media/File:Rock-paper-scissors.svg) under [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/)](assets/rps.png){width=50%}

- Rock defeats scissors, scissors defeats paper, and paper defeats rock
- You get +1 point for a win, -1 for a loss, and 0 for ties

This simple game was the subject of a DeepMind paper in 2023, where they wrote: 

> In sequential decision-making, agent evaluation has largely been restricted to few interactions against experts, with the aim to reach some desired level of performance (e.g. beating a human professional player). We propose a benchmark for multiagent learning based on repeated play of the simple game Rock, Paper, Scissors.

Let's dig in to why RPS is a more interesting game than it might seem. 

### Payoff Matrix
The core features of a game are its players, the actions of each player, and the payoffs. We can show this for RPS in the below payoff matrix, also known as normal-form.

| Player 1/2 | Rock    | Paper   | Scissors |
|--------|---------|---------|----------|
| **Rock**   | (0, 0)  | (-1, 1) | (1, -1)  |
| **Paper**  | (1, -1) | (0, 0)  | (-1, 1)  |
| **Scissors** | (-1, 1) | (1, -1) | (0, 0)   |

The payoffs for Player 1 are on the left and for Player 2 on the right in each payoff outcome of the game. For example, the bottom left payoff is when Player 1 plays Scissors and Player 2 plays Rock, resulting in -1 for P1 and +1 for P2. 

### Expected Value
A strategy says which actions you would take for every state of the game.

**Expected value** represents the average outcome of a strategy if it were repeated many times. It’s calculated by multiplying each possible outcome by its probability of occurrence and then summing these products.

Suppose that  Player 1 plays the strategy: 

$$
\begin{cases}
r = 0.5 \\
p = 0.25 \\
s = 0.25
\end{cases}
$$

and Player 2 plays the strategy: 

$$
\begin{cases}
r = 0.1 \\
p = 0.3 \\
s = 0.6
\end{cases}
$$

Let's add these to the matrix: 

| Player 1/2 | Rock ($r_2=0.1$)   | Paper ($p_2=0.3$)  | Scissors ($s_2=0.6$) |
|--------|---------|---------|----------|
| **Rock ($r_1=0.5$)**  | (0, 0)  | (-1, 1) | (1, -1)  |
| **Paper ($p_1=0.25$)** | (1, -1) | (0, 0)  | (-1, 1)  |
| **Scissors ($s_1=0.25$)** | (-1, 1) | (1, -1) | (0, 0)   |

To simplify, let's just write the payoffs for Player 1 since payoffs for Player 2 will simply be the inverse: 

| Player 1/2 | Rock ($r_2=0.1$)   | Paper ($p_2=0.3$)  | Scissors ($s_2=0.6$) |
|--------|---------|---------|----------|
| **Rock ($r_1=0.5$)**   | 0  | -1 | 1 |
| **Paper ($p_1=0.25$)** | 1 | 0  | -1 |
| **Scissors ($s_1=0.25$)** | -1 | 1 | 0 |

Now we can multiply the player action strategies together to get a percentage occurrence for each payoff in the matrix: 

| Player 1/2 | Rock ($r_2=0.1$)   | Paper ($p_2=0.3$)  | Scissors ($s_2=0.6$) |
|--------|---------|---------|----------|
| **Rock ($r_1=0.5$)**   | Val: 0 <br>Pr: $0.5(0.1) = 0.05$ | Val: -1 <br>Pr: $0.5(0.3) = 0.15$ | Val: 1 <br>Pr: $0.5(0.6) = 0.3$ |
| **Paper ($p_1=0.25$)** | Val: 1 <br>Pr: $0.25(0.1) = 0.025$ | Val: 0  <br>Pr: $0.25(0.3) = 0.075$ | Val: -1 <br>Pr: $0.25(0.6) = .15$ |
| **Scissors ($s_1=0.25$)** | Val: -1 <br>Pr: $0.25(0.1) = 0.025$ | Val: 1 <br>Pr: $0.25(0.3) = 0.075$ | Val: 0 <br>Pr: $0.25(0.6) = .15$ |

Note that the total probabilities sum to 1 and each row and column sums to the probability of playing that row or column. 

We can work out the expected value of the game to Player 1 (summing all payoffs multiplied by probabilities from top left to bottom right): 

$\mathbb{E} = 0(0.05) + -1(0.15) + 1(0.3) + 1(0.025) + 0(0.075) + -1(0.15) + -1(0.025) + 1(0.075) + 0(0.15) = 0.075$

Therefore P1 is *expected* to gain 0.075 per game given these strategies. Since payoffs are reversed for P2, P2's expectation is -0.075 per game. 

### Zero-sum
We see in the matrix that every payoff is zero-sum, i.e. the sum of the payoffs to both players is 0. This means the game is one of pure competition. Any amount P1 wins is from P2 and vice versa. 

### Nash equilibrium
A Nash equilibrium means that no player can improve their expected payoff by unilaterally changing their strategy. That is, changing one's strategy can only result in the same or worse payoff (assuming the other player does not change). 

In RPS, the Nash equilibrium strategy is to play each action $r = p = s = 1/3$ of the time. I.e., to play totally randomly. 

This is called a mixed strategy, as opposed to a pure strategy, which would select only one action. Mixed strategies are useful in games of imperfect information because it's valuable to not be predictable and to conceal your private information. In perfect information games, the theoretically optimal play would not contain any mixing (i.e., if you could calculate all possible moves to the end of the game). 

The equilibrium RPS strategy is worked out below: 

:::{.callout-tip collapse="true" appearance="minimal"}
## Nash equilibrium strategy for RPS
| Player 1/2 | Rock   | Paper  | Scissors |
|--------|---------|---------|----------|
| **Rock ($r$)**  | (0, 0)  | (-1, 1) | (1, -1)  |
| **Paper ($p$)** | (1, -1) | (0, 0)  | (-1, 1)  |
| **Scissors ($s$)** | (-1, 1) | (1, -1) | (0, 0)   |

If Player 1 plays Rock with probability $r$, Paper with probability $p$, and Scissors with probability $s$, we have the following expected value equations for Player 2: 

$\mathbb{E_2}(\text{R}) = -1p + 1s$

$\mathbb{E_2}(\text{P}) = 1r - 1s$

$\mathbb{E_2}(\text{S}) = -1r + 1p$

(To see each of these, sum the payoffs for each column with P2 payoffs and P1 probabilities.)

Since no action dominates, we know that the EV of every strategic action should be equal  (since if a certain strategy was best, we'd want to always play that strategy). 

To solve for $r$, $p$, and $s$, we can start by setting these EVs equal: 

$\mathbb{E_2}(\text{R}) = \mathbb{E_2}(\text{P})$

$-1p + 1s = 1r - 1s$

$2s = p + r$

Then setting these equal: 

$\mathbb{E_2}(\text{R}) = \mathbb{E_2}(\text{S})$

$-1p + 1s = -1r + 1p$

$s + r = 2p$

And finally setting these equal: 

$\mathbb{E_2}(\text{P}) = \mathbb{E_2}(\text{S})$

$1r - 1s = -1r + 1p$

$2r = s + p$

Now we have these equations:  

$$
\begin{cases}
2s = p + r \\
s + r = 2p \\
2r = s + p
\end{cases}
$$

We can rewrite the 1st: 

$r = 2s - p$

And combine with the 2nd: 

$s + (2s - p) = 2p$

$3s = 3p$

Resulting in: 

$s = p$

Now we can go back to the 2nd equation: 

$s + r = 2p$

And insert $s$ = $p$: 

$s + r = 2s$

And arrive at: 

$r = s$

We now see that all are equal: 

$s = p = r$

We also know that they must all sum to $1$: 

$r + p + s = 1$

Since they're all equal and sum to $1$, we can substitute $p$ and $s$ with $r$: 

$3r = 1$

$r = 1/3$

So all actions are taken with probability $1/3$: 

$r = p = s = 1/3 \quad \blacksquare$

By symmetry, the same equilibrium strategy is true for Player 2. 
:::

Playing this strategy means that whatever your opponent does, you will breakeven! For example, think about an opponent that always plays Rock. 

$$
\begin{equation}
\begin{split}
\mathbb{E}(\text{Equilibrium vs. Rock}) &= 0(r) + 1(p) + -1(s) \\
&= 0(1/3) + 1(1/3) + -1(1/3) \\
&= 0
\end{split}
\end{equation}
$$

How about the case of the opponent playing 60% Rock, 20% Paper, 20% Scissors? 

$$
\begin{equation}
\begin{split}
\mathbb{E}(\text{Equilibrium vs. 622}) &= 0.6(\text{Result vs. Rock}) \\ 
+ 0.2(\text{Result vs. Paper}) \\  
+ 0.2(\text{Result vs. Scissors}) \\
&= 0.6(0) + 0.2(0) + 0.2(0)
&= 0
\end{split}
\end{equation}
$$

The random strategy will result in 0 against any pure strategy and any combination of strategies including the random strategy. 

### Exploiting vs. Nash
The equilibrium strategy vs. a pure Rock opponent is a useful illustration of the limitations of playing at equilibrium. The Rock opponent is playing the worst possible strategy, yet equilibrium is still breaking even! 

What's the best that we could do against Rock only? We could play **purely paper**. 

$$
\begin{equation}
\begin{split}
\mathbb{E}(\text{Paper vs. Rock Only}) &= 1(r) + 0(p) + -1(s) && \Rightarrow \text{Paper vs. all opponent probs} \\
&= 1(1) + 0(0) + -1(0) && \Rightarrow \text{Opponent only plays } r \\
&= 1
\end{split}
\end{equation}
$$

We'd win 1 each game playing Paper vs. Rock. 

How about against the opponent playing 60% Rock, 20% Paper, 20% Scissors? Here we can see that because they are overplaying Rock, our best strategy is again to always play Paper.

$$
\begin{equation}
\begin{split}
\mathbb{E}(\text{Paper vs. 622}) &= 1(r) + 0(p) + -1(s) && \Rightarrow \text{Paper vs. all opponent probs} \\
&= 1(0.6) + 0(0.2) + -1(0.2) && \Rightarrow \text{Opponent plays } 622 \\
&= 0.6 + 0 - 0.2 
&= 0.4
\end{split}
\end{equation}
$$

## Soccer Kicker vs. Goalie
Consider the **Soccer Penalty Kick** game where a Kicker is trying to score a goal and the Goalie is trying to block it. 

| Kicker/Goalie | Lean Left | Lean Right | 
|------------|-----------|--------|
| Kick Left  | 0, 0  | +2, -2 |
| Kick Right | +1, -1 | 0, 0|

The game setup is zero-sum. If Kicker and Goalie both go in one direction, then it’s assumed that the goal will miss and both get $0$ payoffs. If the Kicker plays Kick Right when the Goalie plays Lean Left, then the Kicker is favored and gets a payoff of $+1$. If the Kicker plays Kick Left when the Goalie plays Lean Right, then the kicker is even more favored, because it’s easier to kick left than right, and gets $+2$.

:::{.callout-note  appearance="minimal"}
## Nash Equilibrium Exercise

Which of these, if any, is a Nash equilibrium? You can check by seeing if either player would benefit by changing their action. 

| Kicker | Goalie | Equilibrium or Change? | 
|------------|-----------|--------|
| Left  | Left  |  |
| Left | Right | |
| Right | Left | |
| Right | Right | |

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution

There are no pure Nash equilibrium solutions because when the actions match, the Kicker will always want to change, and when they don’t match, the Goalie will always want to change. 

| Kicker | Goalie | Equilibrium or Change? | 
|------------|-----------|--------|
| Left  | Left  | Kicker changes to right  |
| Left | Right | Goalie changes to left |
| Right | Left | Goalie changes to right |
| Right | Right | Kicker changes to left |
:::


:::{.callout-note  appearance="minimal"}
## Expected Value Exercise
Assume that they both play Left 50% and Right 50% -- what is the expected value of the game? 

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution

| Kicker/Goalie | Lean Left (0.5) | Lean Right (0.5) | 
|------------|-----------|--------|
| Kick Left (0.5) | 0, 0  | +2, -2 |
| Kick Right (0.5) | +1, -1 | 0, 0|

We apply these probabilities to each of the 4 outcomes: 

| Kicker/Goalie | Lean Left (0.5) | Lean Right (0.5) | 
|------------|-----------|--------|
| Kick Left (0.5) | 0, 0 (0.25) | +2, -2 (0.25) |
| Kick Right (0.5) | +1, -1 (0.25) | 0, 0 (0.25) |

Now for the Kicker, we have $\mathbb{E} = 0.25*0 + 0.25*2 + 0.25*1 + 0.25*0 = 0.75$. 

Since it's zero-sum, we have $\mathbb{E} = -0.75$ for the Goalie.

Note that, for example, the Kicker playing 50% Left and 50% Right could be interpreted as a single player having these probabilities or a field of players averaging to these probabilities. So out of 100 players, this could mean: 

- 100 players playing 50% Left and 50% Right
- 50 players playing 100% Left and 50 players playing 100% Right
- 50 players playing 75% Left/25% Right and 50 players playing 25% Left/75% right

:::

When the Goalie plays left with probability $p$ and right with probability $1-p$, we can find the expected value of the Kicker actions.

| Kicker/Goalie | Lean Left (p) | Lean Right (1-p) | 
|------------|-----------|--------|
| Kick Left | 0, 0  | +2, -2 |
| Kick Right | +1, -1 | 0, 0|

$\mathbb{E}(\text{Kick Left}) = 0*p + 2*(1-p) = 2 - 2*p$

$\mathbb{E}(\text{Kick Right}) = 1*p + 0*(1-p) = 1*p$

The Kicker is going to play the best response to the Goalie’s strategy. The Goalie wants to make the Kicker **indifferent** to Kick Left and Kick Right because if the Kicker was not going to be indifferent, then he would prefer one of the actions, meaning that action would be superior to the other. Therefore the Kicker will play a mixed strategy in response that will result in a Nash equilibrium where neither player benefits from unilaterally changing strategies. (Note that indifferent does not mean 50% each, but means the expected value is the same for each.)

![](assets/kickergoalieplot.png)

By setting the values equal, we get $2 - 2*p = 1*p \Rightarrow p = \frac{2}{3}$ as shown in the plot. This means that $1-p = 1 - \frac{2}{3} = \frac{1}{3}$. Therefore the Goalie should play Lean Left $\frac{2}{3}$ and Lean Right $\frac{1}{3}$. The value for the Kicker is $\frac{2}{3}$, or $(0.67)$, for both actions, regardless of the Kicker's mixing strategy. 

Note that the Kicker is worse off now ($0.67$ now compared to $0.75$) than when both players played 50% each action. Why?

If the Kicker plays Left with probability $q$ and Right with probability $1-q$, then the Goalie’s values are: 

$\mathbb{E}(\text{Lean Left}) = 0*q - 1*(1-q) = -1 + q$

$\mathbb{E}(\text{Lean Right}) = -2*q + 0 = -2*q$

Setting equal, 

$$
\begin{equation}
\begin{split}
-1 + q &= -2*q \\
-1 &= -3*q  \\
\frac{1}{3} &= q
\end{split}
\end{equation}
$$

Therefore the Kicker should play Left $\frac{1}{3}$ and Right $\frac{2}{3}$, giving a value of $-\frac{2}{3}$ to the Goalie. 

We can see this from the game table: 

| Kicker/Goalie | Lean Left ($\frac{2}{3}$) | Lean Right ($\frac{1}{3}$) | 
|------------|-----------|--------|
| Kick Left ($\frac{1}{3}$) | 0, 0 ($\frac{2}{9}$) | +2, -2 ($\frac{1}{9}$) |
| Kick Right ($\frac{2}{3}$) | +1, -1 ($\frac{4}{9}$) | 0, 0 ($\frac{2}{9}$)|

Therefore the expected payoffs in this game are $\frac{2}{9}*0 + \frac{1}{9}*2 + \frac{4}{9}*1 + \frac{2}{9}*0 = \frac{6}{9} = 0.67$ for the Kicker and $-0.67$ for the Goalie. 

In an equilibrium, no player should be able to unilaterally improve by changing their strategy. What if the Kicker switches to always Kick Left?

| Kicker/Goalie | Lean Left ($\frac{2}{3}$) | Lean Right ($\frac{1}{3}$) | 
|------------|-----------|--------|
| Kick Left ($1$) | 0, 0 ($\frac{2}{3}$) | +2, -2 ($\frac{1}{3}$) |
| Kick Right ($0$) | +1, -1 ($0$) | 0, 0 ($0$)|

Now the Kicker's payoff is still $\frac{1}{3}*2 = 0.67$. 

When a player makes their opponent indifferent, this means that any action the opponent takes (within the set of equilibrium actions) will result in the same payoff! 

So if you know your opponent is playing the equilibrium strategy, then you can actually do whatever you want with no penalty with the mixing actions. Sort of. 

The risk is that the opponent can now deviate from equilibrium and take advantage of your new strategy. For example, if the Goalie caught on and moved to always Lean Left, then expected value is reduced to $0$ for both players. 

To summarize, you can only be penalized for not playing the equilibrium mixing strategy if your opponent plays a non-equilibrium strategy that exploits your strategy. 

:::{.callout-note  appearance="minimal"}
## Indifference
Why do players make their opponent indifferent?
:::

## Indifference in Poker 
Back to poker. We can apply this indifference principle in computing equilibrium strategies in poker. When you make your opponent indifferent, then you don’t give them any best play. 

Important note: If you play an equilibrium strategy, opponents will only get penalized for playing hands outside of the set of hands in the mixed strategy equilibrium (also known as the support, or the set of pure strategies that are played with non-zero probability under the mixed strategy). If opponents are not playing equilibrium, though, then they open themselves up to exploitation. 

Let’s look at one particular situation in Kuhn Poker and work it out by hand. Suppose that you are Player 2 with card Q after a Check from Player 1.

![](assets/kuhnindiff.png)

:::{.callout-note  appearance="minimal"}
## Expected Value Exercise
What indifference is Player 2 trying to induce? Compute it.

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution
Making P1 indifferent between calling and folding with a K 

We can work out Player 2's betting strategy by calculating the indifference. Let $b$ be the probability that P2 bets with a Q after P1 checks. 

\begin{equation}
\begin{split}
\mathbb{E}(\text{P1 Check K then Fold to Bet}) &= 0 \\
\\

\mathbb{E}(\text{P1 Check K then Call Bet}) &= -1*\Pr(\text{P2 has A and Bets}) + 3*\Pr(\text{P2 has Q and Bets}) \\
  &= -1*\frac{1}{2} + 3*\frac{1}{2}*b \\
  &= -0.5 + 1.5*b
\end{split}
\end{equation}

Setting these equal: 

$0 = -0.5 + 1.5*b$ 

$b = \frac{1}{3}$

Therefore in equilibrium, P2 should bet $\frac{1}{3}$ with Q after P1 checks.  
:::

:::{.callout-note  appearance="minimal"}
## Equilibrium Mixed Strategy Change Exercise
If P2 bet $\frac{2}{3}$ instead of $\frac{1}{3}$ with Q after P1 checks and P1 is playing an equilibrium strategy, how would P2’s expected value change? 

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution
It wouldn't! As long as P1 doesn't modify their equilibrium strategy, then P2 can mix his strategy (at mixing infosets) however he wants and have the same EV. 

:::

:::{.callout-note  appearance="minimal"}
## Bluff:Value Ratio Exercise
Given that P2 has bet after P1 checks and is playing the equilibrium strategy, what is the probability that they are bluffing?

(Note: Including cases where you have an A, so Q bets are bluffs and A bets are value bets.)

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution
P2 has Q and A each $\frac{1}{2}$ of the time. 

P2 is betting Q $\frac{1}{3}$ of the time (bluffing). 

P2 is betting A always (value betting). 

Therefore for every 3 times you have Q you will bet once and for every 3 times you have A you will bet 3 times. Out of the 4 bets, 1 of them is a bluff. 

$\Pr(\text{P2 Bluff after P1 Check}) = \frac{1}{4}$

:::

### Deviating from Nash

Best response to each other in equilibrium, no incentive to deviate. 
Deviate means no longer in equilibrium, though EV is same. 
only guarantee worst-case payoff of 0 if you randomize

### Indifference 
why is fundamental goal to make other player indifferent?
if deviate, 
indifference guarantees can't improve by changing unliterally 


## Clairvoyance Poker 
Back to poker. We previously built **Face-up 3-card Poker** where each player was dealt a card from the deck of {0, 1, 2} and the high card won. 

Now we're going to make the game more interesting. 

- Player 1 will *always* be dealt card 1. 

- Player 2 will be dealt randomly from {0, 2}.

- P1 knows P2 has either card 0 or 2, but not which. P2 knows that P1 has card 1. 

Let's modify the code: 

:::{.callout-tip collapse="true" appearance="minimal"}
### Update `deal_cards` function
```python
    def deal_cards(self):
        self.cards[0] = 1
        remaining_cards = [card for card in self.deck if card != self.cards[0]]
        self.cards[1] = random.choice(remaining_cards)
```
:::

### Equity in Poker
show same equity 

### Betting Rules and Sequences 
- Both players ante 1 chip, so the starting pot is 2

- Player 1 acts first and can either Bet 1 or Check (Pass)

    - If P1 Bets, P2 can Call or Fold

    - If P1 Checks, P2 can Bet or Check

        - If P1 Passes and P2 Bets, P1 can Call or Fold

There are three possible ways for the hand to end: 

- Check Check: Pot 2, hands go to *showdown* and player with highest card wins 1 (the ante)
- Bet Call: Pot 4, hands go to *showdown* and player with highest card wins 2 (the ante + bet)
- Bet Fold: Pot 3, player who bets wins 1 (the ante)

--> Add pot size stuff 

### Starting Strategies
Let's hard-code some initial strategies for both players. 

- P1: Randomly bet/check
- P2 after bet: Call with card 2 and fold with card 0
- P2 after check: Bet with card 2 and randomize between bet/check with card 0

This strategy randomizes uncertain decisions and takes clearly smart decisions when possible. 

What does that mean? 

- P2 call with card 2 after P1 bet: This is the best hand and guarantees a win

- P2 fold with card 0 after P1 bet: This is the worst card and can't win

- P2 bet with card 2 after P1 check: This is the best card and betting can only possibly win additional chips

---> show wins/losses, frequency, total for each strategic decision
P1 bet, P1 check/call, P1 check/fold
P2 0 after bet call, P2 0 after bet fold, P2 0 after check bet, P2 0 after check check
P2 2 after bet call, P2 2 after bet fold, P2 2 after check bet, P2 2 after check check

### Dominated Strategy 
Note that P1 betting is strictly worse and why 

### Your Strategies
---> Try strat for P1 then for P2
See results

### Indifference in Poker 
Figuring out strategy for 0 facing check, actually thinking about strategy for 0 and 2. goal indifference

EV folding 0, EV calling should also be 0 

shows EV = bluff*3 - value*1 (but this is for overall range 1/4 bluffs)

bluff to value ratio bet/(bet+pot)

Figuring out strategy for 1 after check/bet

bluffing frequency goes up as bet size gets larger relative to pot

Only mix when both same EV 


call strategy wants indifferent between betting and checking card 0 
checking 0 has EV 0
betting 0 also needs to have EV 0

EV = fold*2 - call*1
get call = 2/3 
1 - bet/(bet+pot)
larger bet means call less, let them get away with bluffs the bigger they bet

### Equity vs. Expected Value 
can tell opponent strategy to bet 1/3 0s but can't stop 
call more catches more bluffs, but pays off more value bets

Sometimes have to bluff with bad cards because EV higher than if you 
always folded with bad cards. 

Add uncertainty the opponent has to think about in counter-strategy
If always folded bad cards, opponent knows you keep playing with good # 

### Bonus: Ideal Bet Size
